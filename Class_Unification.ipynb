{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beb4722b",
        "outputId": "b341b1e0-6a08-4166-d163-676beccf9d05"
      },
      "source": [
        "import yaml\n",
        "\n",
        "file_path = '/content/drive/MyDrive/Colabim/bdp/training_data/data.yaml'\n",
        "\n",
        "try:\n",
        "    with open(file_path, 'r') as file:\n",
        "        yaml_content = yaml.safe_load(file)\n",
        "    print(yaml_content)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file '{file_path}' was not found.\")\n",
        "except yaml.YAMLError as e:\n",
        "    print(f\"Error parsing YAML file: {e}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'names': ['crow', 'pigeon', 'plane', 'seagull', 'stork', 'swallow', 'unknown_bird'], 'nc': 7, 'path': '/content/drive/MyDrive/Colabim/bdp/training_data', 'train': '/content/drive/MyDrive/Colabim/bdp/training_data/train/images', 'val': '/content/drive/MyDrive/Colabim/bdp/training_data/val/images'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a1c39a9"
      },
      "source": [
        "cp -r /content/drive/MyDrive/Colabim/bdp/training_data /content/drive/MyDrive/Colabim/bdp__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0d56036",
        "outputId": "d96b1dfe-3ff5-40da-a93b-86eb5e4a822c"
      },
      "source": [
        "pip install ultralytics"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.216-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.10.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.216-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.216 ultralytics-thop-2.0.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edf98b4d"
      },
      "source": [
        "## Filter bounding boxes by size\n",
        "\n",
        "### Subtask:\n",
        "Iterate through the relabeled label files, calculate the bounding box area in pixels for each entry, and keep only those with an area of 80 square pixels or more."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "751874a3"
      },
      "source": [
        "**Reasoning**:\n",
        "Iterate through each relabeled label file, calculate the bounding box area using the provided image dimensions, filter out bounding boxes smaller than the specified threshold, and store the filtered lines."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a593db0b",
        "outputId": "84ad5417-cb19-40ce-dfca-d9f8090a5402"
      },
      "source": [
        "import os\n",
        "\n",
        "filtered_relabeled_data = {}\n",
        "image_width = 1920\n",
        "image_height = 1080\n",
        "area_threshold = 80\n",
        "\n",
        "for file_name, lines in relabeled_data.items():\n",
        "    filtered_lines = []\n",
        "    for line in lines:\n",
        "        parts = line.strip().split()\n",
        "        if len(parts) == 5: # Expecting class_id, center_x, center_y, width, height\n",
        "            try:\n",
        "                # YOLO format: <class_id> <center_x> <center_y> <width> <height> (normalized)\n",
        "                # Bounding box coordinates are normalized to the image size.\n",
        "                # To get pixel values, multiply by image dimensions.\n",
        "                class_id = int(parts[0])\n",
        "                center_x = float(parts[1])\n",
        "                center_y = float(parts[2])\n",
        "                width_normalized = float(parts[3])\n",
        "                height_normalized = float(parts[4])\n",
        "\n",
        "                # Convert normalized width and height to pixel values\n",
        "                width_pixels = width_normalized * image_width\n",
        "                height_pixels = height_normalized * image_height\n",
        "\n",
        "                # Calculate area in pixels\n",
        "                area_pixels = width_pixels * height_pixels\n",
        "\n",
        "                if area_pixels >= area_threshold:\n",
        "                    filtered_lines.append(line)\n",
        "            except ValueError:\n",
        "                print(f\"Warning: Skipping malformed line in file {file_name}: {line.strip()}\")\n",
        "        else:\n",
        "            print(f\"Warning: Skipping malformed line with incorrect number of parts in file {file_name}: {line.strip()}\")\n",
        "\n",
        "    filtered_relabeled_data[file_name] = filtered_lines\n",
        "\n",
        "# Display a sample of the filtered data for one file\n",
        "if filtered_relabeled_data:\n",
        "    sample_file_name = list(filtered_relabeled_data.keys())[0]\n",
        "    print(f\"Sample filtered data for {sample_file_name}:\")\n",
        "    for line in filtered_relabeled_data[sample_file_name][:5]: # Print only the first 5 lines\n",
        "        print(line)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample filtered data for frame_000165.txt:\n",
            "6 0.106526 0.014102 0.016875 0.017852\n",
            "6 0.161758 0.256528 0.025526 0.012778\n",
            "6 0.041156 0.132102 0.025729 0.009537\n",
            "6 0.155328 0.246898 0.017969 0.018148\n",
            "6 0.934201 0.091556 0.017495 0.013500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff314f41"
      },
      "source": [
        "## Save filtered label files\n",
        "\n",
        "### Subtask:\n",
        "Overwrite the label files in the new data directory with the filtered content."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "397c93b7"
      },
      "source": [
        "**Reasoning**:\n",
        "Iterate through the filtered_relabeled_data dictionary and write the filtered content to the original label files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9568896",
        "outputId": "950c6681-7757-46f6-b55f-f9e4f720cf91"
      },
      "source": [
        "import os\n",
        "\n",
        "labels_dir = os.path.join('/content/drive/MyDrive/Colabim/bdp/KARGA3_m', 'labels', 'train')\n",
        "\n",
        "for file_name, lines in filtered_relabeled_data.items():\n",
        "    file_path = os.path.join(labels_dir, file_name)\n",
        "    with open(file_path, 'w') as file:\n",
        "        for line in lines:\n",
        "            file.write(line + '\\n')\n",
        "\n",
        "print(\"Filtered data successfully written to original label files.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered data successfully written to original label files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4931097a"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "* Bounding boxes with an area less than 80 square pixels have been filtered out from the label files in `/content/drive/MyDrive/Colabim/bdp/KARGA3_m/labels/train`.\n",
        "* The original label files have been overwritten with the filtered content.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "* The label files in the new dataset now only contain bounding boxes that meet the specified size threshold, further preparing them for integration with the existing training data.\n",
        "* The next step would be to integrate these processed label files and their corresponding image files into the existing training data structure or pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2655effe",
        "outputId": "8be66794-959c-4760-d809-df2c35ae3737"
      },
      "source": [
        "get_ipython().system('unzip /content/drive/MyDrive/Colabim/KARGA3_m.zip -d /content/drive/MyDrive/Colabim/bdp/KARGA3_m')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/Colabim/KARGA3_m.zip\n",
            " extracting: /content/drive/MyDrive/Colabim/bdp/KARGA3_m/train.txt  \n",
            " extracting: /content/drive/MyDrive/Colabim/bdp/KARGA3_m/data.yaml  \n",
            " extracting: /content/drive/MyDrive/Colabim/bdp/KARGA3_m/images/train/frame_000300.png  \n",
            " extracting: /content/drive/MyDrive/Colabim/bdp/KARGA3_m/images/train/frame_000645.png  \n",
            " extracting: /content/drive/MyDrive/Colabim/bdp/KARGA3_m/images/train/frame_000735.png  \n",
            " extracting: /content/drive/MyDrive/Colabim/bdp/KARGA3_m/images/train/frame_000720.png  \n",
            " extracting: /content/drive/MyDrive/Colabim/bdp/KARGA3_m/images/train/frame_000180.png  \n",
            " extracting: /content/drive/MyDrive/Colabim/bdp/KARGA3_m/images/train/frame_000090.png  \n",
            " extracting: /content/drive/MyDrive/Colabim/bdp/KARGA3_m/images/train/frame_000630.png  \n",
            " extracting: /content/drive/MyDrive/Colabim/bdp/KARGA3_m/images/train/frame_000315.png  \n",
            " extracting: /content/drive/MyDrive/Colabim/bdp/KARGA3_m/images/train/frame_000165.png  \n",
            " extracting: /content/drive/MyDrive/Colabim/bdp/KARGA3_m/images/train/frame_000705.png  \n",
            " extracting: /content/drive/MyDrive/Colabim/bdp/KARGA3_m/images/train/frame_000345.png  \n",
            " extracting: /content/drive/MyDrive/Colabim/bdp/KARGA3_m/images/train/frame_000615.png  \n",
            " extracting: /content/drive/MyDrive/Colabim/bdp/KARGA3_m/images/train/frame_000750.png  \n",
            " extracting: /content/drive/MyDrive/Colabim/bdp/KARGA3_m/images/train/frame_000600.png  \n",
            " extracting: /content/drive/MyDrive/Colabim/bdp/KARGA3_m/images/train/frame_000240.png  \n",
            " extracting: /content/drive/MyDrive/Colabim/bdp/KARGA3_m/images/train/frame_000330.png  \n",
            " extracting: /content/drive/MyDrive/Colabim/bdp/KARGA3_m/images/train/frame_000765.png  \n",
            " extracting: /content/drive/MyDrive/Colabim/bdp/KARGA3_m/images/train/frame_000675.png  \n",
            " extracting: /content/drive/MyDrive/Colabim/bdp/KARGA3_m/labels/train/frame_000165.txt  \n",
            " extracting: /content/drive/MyDrive/Colabim/bdp/KARGA3_m/labels/train/frame_000345.txt  \n",
            " extracting: /content/drive/MyDrive/Colabim/bdp/KARGA3_m/labels/train/frame_000705.txt  \n",
            " extracting: /content/drive/MyDrive/Colabim/bdp/KARGA3_m/labels/train/frame_000675.txt  \n",
            " extracting: /content/drive/MyDrive/Colabim/bdp/KARGA3_m/labels/train/frame_000330.txt  \n",
            " extracting: /content/drive/MyDrive/Colabim/bdp/KARGA3_m/labels/train/frame_000240.txt  \n",
            " extracting: /content/drive/MyDrive/Colabim/bdp/KARGA3_m/labels/train/frame_000180.txt  \n",
            " extracting: /content/drive/MyDrive/Colabim/bdp/KARGA3_m/labels/train/frame_000090.txt  \n",
            " extracting: /content/drive/MyDrive/Colabim/bdp/KARGA3_m/labels/train/frame_000315.txt  \n",
            " extracting: /content/drive/MyDrive/Colabim/bdp/KARGA3_m/labels/train/frame_000300.txt  \n",
            " extracting: /content/drive/MyDrive/Colabim/bdp/KARGA3_m/labels/train/frame_000645.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e52372d"
      },
      "source": [
        "## Load class names\n",
        "\n",
        "### Subtask:\n",
        "Read the class names from the `data.yaml` file in the existing training data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "770a5a1a"
      },
      "source": [
        "**Reasoning**:\n",
        "Extract the class names from the loaded YAML content.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef1c14a2",
        "outputId": "b61f2946-88c5-40a1-d5bb-569e3b7ae278"
      },
      "source": [
        "existing_class_names = yaml_content['names']\n",
        "print(existing_class_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['crow', 'pigeon', 'plane', 'seagull', 'stork', 'swallow', 'unknown_bird']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5d9e654"
      },
      "source": [
        "## Identify new data label files\n",
        "\n",
        "### Subtask:\n",
        "Locate all the label files (e.g., `.txt` files) in the newly unzipped data directory (`/content/drive/MyDrive/Colabim/bdp/KARGA3_m`).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88e2b9c9"
      },
      "source": [
        "**Reasoning**:\n",
        "Locate all the label files (e.g., `.txt` files) in the newly unzipped data directory (`/content/drive/MyDrive/Colabim/bdp/KARGA3_m`).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7175c84",
        "outputId": "12b3b488-e81a-408f-8a65-318a5115649a"
      },
      "source": [
        "import os\n",
        "\n",
        "new_data_dir = '/content/drive/MyDrive/Colabim/bdp/KARGA3_m'\n",
        "labels_dir = os.path.join(new_data_dir, 'labels', 'train')\n",
        "all_files = os.listdir(labels_dir)\n",
        "new_label_files = [f for f in all_files if f.endswith('.txt')]\n",
        "print(new_label_files)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['frame_000165.txt', 'frame_000345.txt', 'frame_000705.txt', 'frame_000675.txt', 'frame_000330.txt', 'frame_000240.txt', 'frame_000180.txt', 'frame_000090.txt', 'frame_000315.txt', 'frame_000300.txt', 'frame_000645.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32328634"
      },
      "source": [
        "## Determine class mapping\n",
        "\n",
        "### Subtask:\n",
        "Understand the mapping between the class indices in the new data's label files and the class names. This might require examining a `data.yaml` file within the new data (if one exists) or getting this information from the user.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a590eff"
      },
      "source": [
        "**Reasoning**:\n",
        "Check for the existence of `data.yaml` in the new data directory, load it if it exists, extract the class names, and compare them to the existing class names to determine the mapping.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b82c695",
        "outputId": "87da1969-d127-49fd-a745-1403b80cdbfe"
      },
      "source": [
        "import os\n",
        "import yaml\n",
        "\n",
        "new_data_dir = '/content/drive/MyDrive/Colabim/bdp/KARGA3_m'\n",
        "new_data_yaml_path = os.path.join(new_data_dir, 'data.yaml')\n",
        "\n",
        "if os.path.exists(new_data_yaml_path):\n",
        "    try:\n",
        "        with open(new_data_yaml_path, 'r') as file:\n",
        "            new_yaml_content = yaml.safe_load(file)\n",
        "        new_class_names = new_yaml_content.get('names')\n",
        "\n",
        "        if new_class_names is not None:\n",
        "            print(\"New data class names:\", new_class_names)\n",
        "            print(\"Existing data class names:\", existing_class_names)\n",
        "\n",
        "            # Determine the mapping\n",
        "            class_mapping = {}\n",
        "            for new_idx, new_name in enumerate(new_class_names):\n",
        "                try:\n",
        "                    existing_idx = existing_class_names.index(new_name)\n",
        "                    class_mapping[new_idx] = existing_idx\n",
        "                except ValueError:\n",
        "                    print(f\"Warning: Class '{new_name}' from new data not found in existing classes.\")\n",
        "                    # Handle classes not found in existing data if necessary, e.g., map to a specific index or skip\n",
        "                    # For this task, we'll just warn and not include it in the mapping if not found.\n",
        "\n",
        "            print(\"Class mapping (new_index: existing_index):\", class_mapping)\n",
        "\n",
        "        else:\n",
        "            print(\"Error: 'names' key not found in the new data's data.yaml file.\")\n",
        "            print(\"Manual input is needed for class mapping.\")\n",
        "\n",
        "    except yaml.YAMLError as e:\n",
        "        print(f\"Error parsing new data's data.yaml file: {e}\")\n",
        "        print(\"Manual input is needed for class mapping.\")\n",
        "else:\n",
        "    print(f\"Error: data.yaml not found in {new_data_dir}.\")\n",
        "    print(\"Manual input is needed for class mapping.\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New data class names: {0: 'pigeon', 1: 'plane', 2: 'unknown_bird', 3: 'stork', 4: 'crow', 5: 'seagull', 6: 'swallow'}\n",
            "Existing data class names: ['crow', 'pigeon', 'plane', 'seagull', 'stork', 'swallow', 'unknown_bird']\n",
            "Warning: Class '0' from new data not found in existing classes.\n",
            "Warning: Class '1' from new data not found in existing classes.\n",
            "Warning: Class '2' from new data not found in existing classes.\n",
            "Warning: Class '3' from new data not found in existing classes.\n",
            "Warning: Class '4' from new data not found in existing classes.\n",
            "Warning: Class '5' from new data not found in existing classes.\n",
            "Warning: Class '6' from new data not found in existing classes.\n",
            "Class mapping (new_index: existing_index): {}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c15961e2"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous output shows that the class names in the new data's `data.yaml` are indexed by numbers instead of being a list of strings, causing the mapping logic to fail. I need to correct the mapping logic to handle this dictionary format and then determine the class mapping based on the class names.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be58cf18",
        "outputId": "d02d9ae5-6d2e-4554-f462-7f35d6097298"
      },
      "source": [
        "# Determine the mapping from new indices to existing indices based on class names\n",
        "class_mapping = {}\n",
        "if isinstance(new_class_names, dict):\n",
        "    # Handle the case where new_class_names is a dictionary\n",
        "    for new_idx, new_name in new_class_names.items():\n",
        "        try:\n",
        "            existing_idx = existing_class_names.index(new_name)\n",
        "            class_mapping[new_idx] = existing_idx\n",
        "        except ValueError:\n",
        "            print(f\"Warning: Class '{new_name}' from new data not found in existing classes.\")\n",
        "else:\n",
        "    # Handle the case where new_class_names is a list (original logic)\n",
        "    for new_idx, new_name in enumerate(new_class_names):\n",
        "        try:\n",
        "            existing_idx = existing_class_names.index(new_name)\n",
        "            class_mapping[new_idx] = existing_idx\n",
        "        except ValueError:\n",
        "            print(f\"Warning: Class '{new_name}' from new data not found in existing classes.\")\n",
        "\n",
        "print(\"Corrected Class mapping (new_index: existing_index):\", class_mapping)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corrected Class mapping (new_index: existing_index): {0: 1, 1: 2, 2: 6, 3: 4, 4: 0, 5: 3, 6: 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "871e8943"
      },
      "source": [
        "## Relabel classes\n",
        "\n",
        "### Subtask:\n",
        "Iterate through each label file in the new data. For each bounding box entry, update the class index based on the mapping determined in the previous step and the class names loaded from the existing `data.yaml`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dffaba7"
      },
      "source": [
        "**Reasoning**:\n",
        "Iterate through each label file, read its contents, update the class indices based on the `class_mapping`, and store the relabeled content in a dictionary.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4599fd42",
        "outputId": "cf3b6cf2-3b70-4c09-95a0-2043da0eeb45"
      },
      "source": [
        "relabeled_data = {}\n",
        "\n",
        "for file_name in new_label_files:\n",
        "    file_path = os.path.join(labels_dir, file_name)\n",
        "    relabeled_lines = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) >= 1:\n",
        "                try:\n",
        "                    old_class_index = int(parts[0])\n",
        "                    if old_class_index in class_mapping:\n",
        "                        new_class_index = class_mapping[old_class_index]\n",
        "                        relabeled_line_parts = [str(new_class_index)] + parts[1:]\n",
        "                        relabeled_lines.append(\" \".join(relabeled_line_parts))\n",
        "                    else:\n",
        "                        # If a class index is not in the mapping, keep the original line or handle as needed\n",
        "                        # For now, we will keep the original line with a warning.\n",
        "                        print(f\"Warning: Class index {old_class_index} in file {file_name} not found in mapping.\")\n",
        "                        relabeled_lines.append(line.strip())\n",
        "                except ValueError:\n",
        "                    # Handle lines that don't start with a valid integer class index\n",
        "                    print(f\"Warning: Skipping malformed line in file {file_name}: {line.strip()}\")\n",
        "                    relabeled_lines.append(line.strip()) # Keep the original line if malformed\n",
        "            else:\n",
        "                 # Handle empty or malformed lines\n",
        "                 print(f\"Warning: Skipping empty or malformed line in file {file_name}: {line.strip()}\")\n",
        "                 relabeled_lines.append(line.strip()) # Keep the original line if malformed\n",
        "\n",
        "    relabeled_data[file_name] = relabeled_lines\n",
        "\n",
        "# Display a sample of the relabeled data for one file\n",
        "if relabeled_data:\n",
        "    sample_file_name = list(relabeled_data.keys())[0]\n",
        "    print(f\"Sample relabeled data for {sample_file_name}:\")\n",
        "    for line in relabeled_data[sample_file_name][:5]: # Print only the first 5 lines\n",
        "        print(line)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample relabeled data for frame_000165.txt:\n",
            "6 0.106526 0.014102 0.016875 0.017852\n",
            "6 0.161758 0.256528 0.025526 0.012778\n",
            "6 0.041156 0.132102 0.025729 0.009537\n",
            "6 0.155328 0.246898 0.017969 0.018148\n",
            "6 0.934201 0.091556 0.017495 0.013500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "688e67ad"
      },
      "source": [
        "## Save modified label files\n",
        "\n",
        "### Subtask:\n",
        "Overwrite the original label files in the new data with the relabeled content.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cac23bd4"
      },
      "source": [
        "**Reasoning**:\n",
        "Iterate through the relabeled_data dictionary and write the relabeled content to the original label files.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7300ffaa",
        "outputId": "aa7cf8b7-fdef-4d92-dba8-148bdf0dc605"
      },
      "source": [
        "for file_name, lines in relabeled_data.items():\n",
        "    file_path = os.path.join(labels_dir, file_name)\n",
        "    with open(file_path, 'w') as file:\n",
        "        for line in lines:\n",
        "            file.write(line + '\\n')\n",
        "\n",
        "print(\"Relabeled data successfully written to original label files.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relabeled data successfully written to original label files.\n"
          ]
        }
      ]
    }
  ]
}